{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "solid-consortium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import ta\n",
    "import os\n",
    "import math\n",
    "import tqdm\n",
    "import keras\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cufflinks as cf\n",
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import metrics\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "MODELS_DIR = \"Models\"\n",
    "DATA_DIR = \"Data\"\n",
    "\n",
    "\n",
    "def next_free_model_name(base_name: str) -> str:\n",
    "    model_files = [name for name in os.listdir(MODELS_DIR) if name.split(\".\")[-1].lower() == \"h5\"]\n",
    "    similar_models_numbers = [int(name.split(\"_\")[-1].split(\".\")[0]) for name in model_files if name.find(base_name) >= 0]\n",
    "    \n",
    "    if len(similar_models_numbers) > 0:\n",
    "        max_value = str(max(similar_models_numbers)+1).zfill(3)\n",
    "        new_name = base_name + \"_\" + max_value\n",
    "    else:\n",
    "        new_name = base_name + \"_000\"\n",
    "    return new_name\n",
    "\n",
    "\n",
    "def infinite_iterator(data: list or tuple or str) -> list or tuple or char or str:\n",
    "    while True:\n",
    "        for item in data:\n",
    "            yield item\n",
    "            \n",
    "\n",
    "def generate_input_sequences(data: pd.DataFrame or np.ndarray, input_length=30, output_length=1) -> np.ndarray:\n",
    "    if type(data) == pd.DataFrame:\n",
    "        price_array = data.to_numpy()\n",
    "    else:\n",
    "        price_array= data\n",
    "    input_sequences = np.zeros((price_array.shape[0] - input_length - output_length,\n",
    "                                input_length, price_array.shape[1]), dtype=float)\n",
    "    for index in range(input_sequences.shape[0]):\n",
    "        input_sequences[index] = price_array[index:index+input_length, :]\n",
    "    return input_sequences\n",
    "\n",
    "\n",
    "def generate_output_sequences(data: pd.DataFrame or np.ndarray, outputs: list,\n",
    "                              input_length=30, output_length=1) -> np.ndarray:\n",
    "    if type(data) == pd.DataFrame:\n",
    "        selected_dataframe = data[outputs]\n",
    "        price_array = selected_dataframe.to_numpy()\n",
    "    else:\n",
    "        price_array = data[:,outputs]\n",
    "        if price_array.ndim == 1:\n",
    "            price_array = price_array.reshape((-1,1))\n",
    "        \n",
    "    if output_length == 1:\n",
    "        output_sequences = np.zeros((price_array.shape[0] - input_length - output_length,\n",
    "                                     price_array.shape[1]), dtype=float)\n",
    "        for index in range(output_sequences.shape[0]):\n",
    "            output_sequences[index] = price_array[index+input_length : index+input_length+output_length, :] \n",
    "    else:\n",
    "        output_sequences = np.zeros((price_array.shape[0] - input_length - output_length,\n",
    "                                     output_length, price_array.shape[1]), dtype=float)\n",
    "        for index in range(output_sequences.shape[0]):\n",
    "            output_sequences[index] = price_array[index+input_length : index+input_length+output_length, :]\n",
    "    return output_sequences\n",
    "\n",
    "\n",
    "def scale_closing_data(data: np.ndarray, max_value: float) -> np.ndarray:\n",
    "    for company in data:\n",
    "#         company[1:,-1] = (company[1:,-1] - company[:-1,-1]) / max_value\n",
    "        company[1:,-1] = company[1:,-1] / max_value\n",
    "    return data\n",
    "\n",
    "\n",
    "def flatten_data(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Stacks mutlidimensional arrays on top of each other reducing their dimensionality by 1 (starting from the higgest dimension)\n",
    "    \"\"\"\n",
    "    new_data = None\n",
    "    for single_read in data:\n",
    "        if new_data is None:\n",
    "            new_data = single_read\n",
    "        else:\n",
    "            new_data = np.append(new_data, single_read, axis=0)   \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def scale_3d_price_data(price_data: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Scale 3d tensor 3rd dimension using sklearn.preprocessing.MinMaxScaler\n",
    "    \"\"\"\n",
    "    scalers = []\n",
    "    scaled_price_data = []\n",
    "    for company in price_data:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(company)\n",
    "        scalers.append(scaler)\n",
    "        scaled_price_data.append(scaler.transform(company))\n",
    "    \n",
    "    return (np.array(scaled_price_data, dtype=object), scalers)\n",
    "\n",
    "\n",
    "def plot_result_verification(results: pd.DataFrame) -> None:\n",
    "    fig = px.line(results, x=\"x\", y=[\"guess\", \"verification\"], animation_frame=\"symbol\",\n",
    "                  color_discrete_sequence=px.colors.qualitative.G10,\n",
    "                  title=\"Results Verificaition\",\n",
    "                  labels={\"guess\": \"predicted closing price\", \n",
    "                          \"verification\": \"verification closing price\",\n",
    "                          \"x\": \"test sample number\"},\n",
    "                  template=\"plotly_white\"\n",
    "                )\n",
    "\n",
    "    for frame_index, frame in enumerate(fig.frames):\n",
    "        company_data = results[results[\"symbol\"] == test_tickers[frame_index]]\n",
    "        lower_y_boundary = min(company_data[\"guess\"].min(), company_data[\"verification\"].min())\n",
    "        upper_y_boundary = max(company_data[\"guess\"].max(), company_data[\"verification\"].max())\n",
    "        frame[\"layout\"] = {\"yaxis\": {\"range\": [lower_y_boundary, upper_y_boundary], \"autorange\": False}}\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title = dict(\n",
    "            y = 0.95,\n",
    "            x = 0.5,\n",
    "            xanchor = \"center\",\n",
    "            yanchor = \"top\",\n",
    "        ),\n",
    "        updatemenus=[dict(buttons=[dict(visible=False)])],\n",
    "        sliders=[dict(x=0, len=1)],\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig.update_yaxes(tickprefix=\"$\", title=\"closing price\")\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def generate_verification_dataframe(model: keras.Model, test_x_segmented: np.ndarray,\n",
    "                                    test_y_segmented: np.ndarray, test_tickers: list) -> pd.DataFrame:\n",
    "    results = pd.DataFrame()\n",
    "    for selected_company in range(len(test_tickers)):\n",
    "        ticker = test_tickers[selected_company]\n",
    "        test_x = test_x_segmented[selected_company]\n",
    "        test_y = test_y_segmented[selected_company]\n",
    "        scaler = test_scalers[selected_company]\n",
    "\n",
    "        single_result = pd.DataFrame()\n",
    "        single_result[\"guess\"] = scaler.inverse_transform(np.repeat(model.predict(test_x), 6, axis=1))[:,-1]\n",
    "        single_result[\"verification\"] = scaler.inverse_transform(np.repeat(test_y, 6, axis=1))[:,-1]\n",
    "        single_result[\"x\"] = np.arange(single_result.shape[0])\n",
    "        single_result[\"symbol\"] = np.repeat(ticker, single_result.shape[0])\n",
    "\n",
    "        results = results.append(single_result, ignore_index=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_losses(history: pd.DataFrame) -> None:\n",
    "    loss = [\"loss\", \"val_loss\"]\n",
    "    fig = px.line(history, y=loss, title=\"Losses During Training\",\n",
    "                  template=\"plotly_white\")\n",
    "    fig.update_layout(\n",
    "        title = dict(\n",
    "            y = 0.9,\n",
    "            x = 0.5,\n",
    "            xanchor = \"center\",\n",
    "            yanchor = \"top\",\n",
    "        ),\n",
    "    )\n",
    "    fig.update_yaxes(title=\"losses [-]\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-burden",
   "metadata": {},
   "source": [
    "# New York Stock Exchange Data\n",
    "Dataset seleceted for project [New York Stock Exchange Data] contains large amount of data separated into 4 files.  \n",
    "____\n",
    "* **fundamentals.csv**  \n",
    "metrics extracted from annual SEC 10K fillings (2012-2016), should be enough to derive most of popular fundamental indicators.\n",
    "----\n",
    "* **securities.csv**  \n",
    "general description of each company with division on sectors  \n",
    "----\n",
    "* **prices-split-adjusted.csv**  \n",
    "same as prices, but there have been added adjustments for splits.\n",
    "----\n",
    "* **prices.csv**  \n",
    "raw, as-is daily prices. Most of data spans from 2010 to the end 2016, for companies new on stock market date range is shorter. There have been approx. 140 stock splits in that time, this set doesn't account for that.\n",
    "----\n",
    "\n",
    "[New York Stock Exchange Data]: <https://www.kaggle.com/dgawlik/nyse?select=prices.csv>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "aggressive-sunday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>30.620001</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>30.590000</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>38409100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>30.850000</td>\n",
       "      <td>30.959999</td>\n",
       "      <td>30.639999</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>49749600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>30.770000</td>\n",
       "      <td>30.520000</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>58182400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>30.629999</td>\n",
       "      <td>30.450001</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>30.700001</td>\n",
       "      <td>50559700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>30.280001</td>\n",
       "      <td>30.660000</td>\n",
       "      <td>30.240000</td>\n",
       "      <td>30.879999</td>\n",
       "      <td>51197400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date symbol       open      close        low       high  \\\n",
       "544   2010-01-04   MSFT  30.620001  30.950001  30.590000  31.100000   \n",
       "1012  2010-01-05   MSFT  30.850000  30.959999  30.639999  31.100000   \n",
       "1480  2010-01-06   MSFT  30.879999  30.770000  30.520000  31.080000   \n",
       "1948  2010-01-07   MSFT  30.629999  30.450001  30.190001  30.700001   \n",
       "2416  2010-01-08   MSFT  30.280001  30.660000  30.240000  30.879999   \n",
       "\n",
       "          volume  \n",
       "544   38409100.0  \n",
       "1012  49749600.0  \n",
       "1480  58182400.0  \n",
       "1948  50559700.0  \n",
       "2416  51197400.0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals = pd.read_csv(DATA_DIR + \"/\" + \"fundamentals.csv\", index_col=0)\n",
    "securities   = pd.read_csv(DATA_DIR + \"/\" + \"securities.csv\")\n",
    "prices       = pd.read_csv(DATA_DIR + \"/\" + \"prices-split-adjusted.csv\")\n",
    "prices[prices[\"symbol\"] == \"MSFT\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "organized-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker Symbol</th>\n",
       "      <th>Period Ending</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>After Tax ROE</th>\n",
       "      <th>Capital Expenditures</th>\n",
       "      <th>Capital Surplus</th>\n",
       "      <th>Cash Ratio</th>\n",
       "      <th>Cash and Cash Equivalents</th>\n",
       "      <th>Changes in Inventories</th>\n",
       "      <th>Common Stocks</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Deferred Asset Charges</th>\n",
       "      <th>Deferred Liability Charges</th>\n",
       "      <th>Depreciation</th>\n",
       "      <th>Earnings Before Interest and Tax</th>\n",
       "      <th>Earnings Before Tax</th>\n",
       "      <th>Effect of Exchange Rate</th>\n",
       "      <th>Equity Earnings/Loss Unconsolidated Subsidiary</th>\n",
       "      <th>Fixed Assets</th>\n",
       "      <th>Goodwill</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>Income Tax</th>\n",
       "      <th>Intangible Assets</th>\n",
       "      <th>Interest Expense</th>\n",
       "      <th>Inventory</th>\n",
       "      <th>Investments</th>\n",
       "      <th>Liabilities</th>\n",
       "      <th>Long-Term Debt</th>\n",
       "      <th>Long-Term Investments</th>\n",
       "      <th>Minority Interest</th>\n",
       "      <th>Misc. Stocks</th>\n",
       "      <th>Net Borrowings</th>\n",
       "      <th>Net Cash Flow</th>\n",
       "      <th>Net Cash Flow-Operating</th>\n",
       "      <th>Net Cash Flows-Financing</th>\n",
       "      <th>Net Cash Flows-Investing</th>\n",
       "      <th>Net Income</th>\n",
       "      <th>Net Income Adjustments</th>\n",
       "      <th>Net Income Applicable to Common Shareholders</th>\n",
       "      <th>Net Income-Cont. Operations</th>\n",
       "      <th>Net Receivables</th>\n",
       "      <th>Non-Recurring Items</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>Operating Margin</th>\n",
       "      <th>Other Assets</th>\n",
       "      <th>Other Current Assets</th>\n",
       "      <th>Other Current Liabilities</th>\n",
       "      <th>Other Equity</th>\n",
       "      <th>Other Financing Activities</th>\n",
       "      <th>Other Investing Activities</th>\n",
       "      <th>Other Liabilities</th>\n",
       "      <th>Other Operating Activities</th>\n",
       "      <th>Other Operating Items</th>\n",
       "      <th>Pre-Tax Margin</th>\n",
       "      <th>Pre-Tax ROE</th>\n",
       "      <th>Profit Margin</th>\n",
       "      <th>Quick Ratio</th>\n",
       "      <th>Research and Development</th>\n",
       "      <th>Retained Earnings</th>\n",
       "      <th>Sale and Purchase of Stock</th>\n",
       "      <th>Sales, General and Admin.</th>\n",
       "      <th>Short-Term Debt / Current Portion of Long-Term Debt</th>\n",
       "      <th>Short-Term Investments</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Total Current Assets</th>\n",
       "      <th>Total Current Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>For Year</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2013-06-30</td>\n",
       "      <td>1.018200e+10</td>\n",
       "      <td>-1.807000e+09</td>\n",
       "      <td>288000000.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-4.257000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>3.804000e+09</td>\n",
       "      <td>-802000000.0</td>\n",
       "      <td>6.730600e+10</td>\n",
       "      <td>2.038500e+10</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.469000e+09</td>\n",
       "      <td>3.755000e+09</td>\n",
       "      <td>2.705200e+10</td>\n",
       "      <td>2.705200e+10</td>\n",
       "      <td>-8000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.991000e+09</td>\n",
       "      <td>1.465500e+10</td>\n",
       "      <td>74.0</td>\n",
       "      <td>5.746400e+10</td>\n",
       "      <td>5.189000e+09</td>\n",
       "      <td>3.083000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.938000e+09</td>\n",
       "      <td>-1.780200e+10</td>\n",
       "      <td>1.841000e+09</td>\n",
       "      <td>1.260100e+10</td>\n",
       "      <td>1.084400e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.537000e+09</td>\n",
       "      <td>-3.134000e+09</td>\n",
       "      <td>2.883300e+10</td>\n",
       "      <td>-8.148000e+09</td>\n",
       "      <td>-2.381100e+10</td>\n",
       "      <td>2.186300e+10</td>\n",
       "      <td>4.590000e+09</td>\n",
       "      <td>2.186300e+10</td>\n",
       "      <td>2.186300e+10</td>\n",
       "      <td>1.911800e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.676400e+10</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.392000e+09</td>\n",
       "      <td>3.388000e+09</td>\n",
       "      <td>2.423600e+10</td>\n",
       "      <td>1.743000e+09</td>\n",
       "      <td>-10000000.0</td>\n",
       "      <td>-1.752000e+09</td>\n",
       "      <td>1.000000e+10</td>\n",
       "      <td>-6.070000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>1.041100e+10</td>\n",
       "      <td>9.895000e+09</td>\n",
       "      <td>-4.429000e+09</td>\n",
       "      <td>2.028900e+10</td>\n",
       "      <td>2.999000e+09</td>\n",
       "      <td>7.321800e+10</td>\n",
       "      <td>1.424310e+11</td>\n",
       "      <td>1.014660e+11</td>\n",
       "      <td>3.741700e+10</td>\n",
       "      <td>7.894400e+10</td>\n",
       "      <td>6.348700e+10</td>\n",
       "      <td>1.424310e+11</td>\n",
       "      <td>7.784900e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>8.376628e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>1.356900e+10</td>\n",
       "      <td>-1.120000e+09</td>\n",
       "      <td>61000000.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-5.485000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>8.669000e+09</td>\n",
       "      <td>-161000000.0</td>\n",
       "      <td>6.836600e+10</td>\n",
       "      <td>2.707800e+10</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.736000e+09</td>\n",
       "      <td>5.212000e+09</td>\n",
       "      <td>2.782000e+10</td>\n",
       "      <td>2.782000e+10</td>\n",
       "      <td>-139000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.301100e+10</td>\n",
       "      <td>2.012700e+10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>5.975500e+10</td>\n",
       "      <td>5.746000e+09</td>\n",
       "      <td>6.981000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.660000e+09</td>\n",
       "      <td>-7.324000e+09</td>\n",
       "      <td>2.562000e+09</td>\n",
       "      <td>2.064500e+10</td>\n",
       "      <td>1.459700e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.962000e+09</td>\n",
       "      <td>4.865000e+09</td>\n",
       "      <td>3.250200e+10</td>\n",
       "      <td>-8.665000e+09</td>\n",
       "      <td>-1.883300e+10</td>\n",
       "      <td>2.207400e+10</td>\n",
       "      <td>4.592000e+09</td>\n",
       "      <td>2.207400e+10</td>\n",
       "      <td>2.207400e+10</td>\n",
       "      <td>2.148500e+10</td>\n",
       "      <td>1.270000e+08</td>\n",
       "      <td>2.775900e+10</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.422000e+09</td>\n",
       "      <td>4.392000e+09</td>\n",
       "      <td>3.005600e+10</td>\n",
       "      <td>3.708000e+09</td>\n",
       "      <td>-39000000.0</td>\n",
       "      <td>-6.024000e+09</td>\n",
       "      <td>1.159400e+10</td>\n",
       "      <td>-6.570000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>1.138100e+10</td>\n",
       "      <td>1.771000e+10</td>\n",
       "      <td>-6.709000e+09</td>\n",
       "      <td>2.048800e+10</td>\n",
       "      <td>2.000000e+09</td>\n",
       "      <td>7.704000e+10</td>\n",
       "      <td>1.723840e+11</td>\n",
       "      <td>1.142460e+11</td>\n",
       "      <td>4.562500e+10</td>\n",
       "      <td>8.978400e+10</td>\n",
       "      <td>8.260000e+10</td>\n",
       "      <td>1.723840e+11</td>\n",
       "      <td>8.683300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>8.298496e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>1.238500e+10</td>\n",
       "      <td>1.456000e+09</td>\n",
       "      <td>346000000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-5.944000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>5.595000e+09</td>\n",
       "      <td>-272000000.0</td>\n",
       "      <td>6.846500e+10</td>\n",
       "      <td>3.303800e+10</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.390000e+09</td>\n",
       "      <td>5.957000e+09</td>\n",
       "      <td>1.850700e+10</td>\n",
       "      <td>1.850700e+10</td>\n",
       "      <td>-73000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.473100e+10</td>\n",
       "      <td>1.693900e+10</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.054200e+10</td>\n",
       "      <td>6.314000e+09</td>\n",
       "      <td>4.835000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.902000e+09</td>\n",
       "      <td>-1.286800e+10</td>\n",
       "      <td>-7.900000e+07</td>\n",
       "      <td>2.780800e+10</td>\n",
       "      <td>1.205300e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.366100e+10</td>\n",
       "      <td>-3.074000e+09</td>\n",
       "      <td>2.966800e+10</td>\n",
       "      <td>-9.668000e+09</td>\n",
       "      <td>-2.300100e+10</td>\n",
       "      <td>1.219300e+10</td>\n",
       "      <td>1.000500e+10</td>\n",
       "      <td>1.219300e+10</td>\n",
       "      <td>1.219300e+10</td>\n",
       "      <td>1.790800e+10</td>\n",
       "      <td>1.001100e+10</td>\n",
       "      <td>1.816100e+10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.117000e+09</td>\n",
       "      <td>5.461000e+09</td>\n",
       "      <td>2.977800e+10</td>\n",
       "      <td>2.522000e+09</td>\n",
       "      <td>362000000.0</td>\n",
       "      <td>-4.189000e+09</td>\n",
       "      <td>1.354400e+10</td>\n",
       "      <td>4.080000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.204600e+10</td>\n",
       "      <td>9.096000e+09</td>\n",
       "      <td>-1.380900e+10</td>\n",
       "      <td>2.032400e+10</td>\n",
       "      <td>7.484000e+09</td>\n",
       "      <td>9.093100e+10</td>\n",
       "      <td>1.744720e+11</td>\n",
       "      <td>1.227970e+11</td>\n",
       "      <td>4.964700e+10</td>\n",
       "      <td>8.008300e+10</td>\n",
       "      <td>9.438900e+10</td>\n",
       "      <td>1.744720e+11</td>\n",
       "      <td>9.358000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.49</td>\n",
       "      <td>8.183221e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>1.303600e+10</td>\n",
       "      <td>-5.300000e+08</td>\n",
       "      <td>-431000000.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-8.343000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>6.510000e+09</td>\n",
       "      <td>600000000.0</td>\n",
       "      <td>6.817800e+10</td>\n",
       "      <td>3.278000e+10</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.917000e+09</td>\n",
       "      <td>6.622000e+09</td>\n",
       "      <td>1.975100e+10</td>\n",
       "      <td>1.975100e+10</td>\n",
       "      <td>-67000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.835600e+10</td>\n",
       "      <td>1.787200e+10</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.254000e+10</td>\n",
       "      <td>2.953000e+09</td>\n",
       "      <td>3.733000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.251000e+09</td>\n",
       "      <td>-1.441700e+10</td>\n",
       "      <td>-9.380000e+08</td>\n",
       "      <td>4.078300e+10</td>\n",
       "      <td>1.043100e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.828300e+10</td>\n",
       "      <td>9.150000e+08</td>\n",
       "      <td>3.332500e+10</td>\n",
       "      <td>-8.393000e+09</td>\n",
       "      <td>-2.395000e+10</td>\n",
       "      <td>1.679800e+10</td>\n",
       "      <td>1.198100e+10</td>\n",
       "      <td>1.679800e+10</td>\n",
       "      <td>1.679800e+10</td>\n",
       "      <td>1.827700e+10</td>\n",
       "      <td>1.110000e+09</td>\n",
       "      <td>2.018200e+10</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.642000e+09</td>\n",
       "      <td>5.892000e+09</td>\n",
       "      <td>3.341700e+10</td>\n",
       "      <td>1.537000e+09</td>\n",
       "      <td>-369000000.0</td>\n",
       "      <td>-1.190000e+09</td>\n",
       "      <td>1.364000e+10</td>\n",
       "      <td>-1.208000e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1.198800e+10</td>\n",
       "      <td>2.282000e+09</td>\n",
       "      <td>-1.530100e+10</td>\n",
       "      <td>1.926000e+10</td>\n",
       "      <td>1.290400e+10</td>\n",
       "      <td>1.067300e+11</td>\n",
       "      <td>1.936940e+11</td>\n",
       "      <td>1.396600e+11</td>\n",
       "      <td>5.935700e+10</td>\n",
       "      <td>7.199700e+10</td>\n",
       "      <td>1.216970e+11</td>\n",
       "      <td>1.936940e+11</td>\n",
       "      <td>8.532000e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2.12</td>\n",
       "      <td>7.923585e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker Symbol Period Ending  Accounts Payable  Accounts Receivable  \\\n",
       "1107          MSFT    2013-06-30      1.018200e+10        -1.807000e+09   \n",
       "1108          MSFT    2014-06-30      1.356900e+10        -1.120000e+09   \n",
       "1109          MSFT    2015-06-30      1.238500e+10         1.456000e+09   \n",
       "1110          MSFT    2016-06-30      1.303600e+10        -5.300000e+08   \n",
       "\n",
       "      Add'l income/expense items  After Tax ROE  Capital Expenditures  \\\n",
       "1107                 288000000.0           28.0         -4.257000e+09   \n",
       "1108                  61000000.0           25.0         -5.485000e+09   \n",
       "1109                 346000000.0           15.0         -5.944000e+09   \n",
       "1110                -431000000.0           23.0         -8.343000e+09   \n",
       "\n",
       "      Capital Surplus  Cash Ratio  Cash and Cash Equivalents  \\\n",
       "1107              0.0       206.0               3.804000e+09   \n",
       "1108              0.0       188.0               8.669000e+09   \n",
       "1109              0.0       194.0               5.595000e+09   \n",
       "1110              0.0       191.0               6.510000e+09   \n",
       "\n",
       "      Changes in Inventories  Common Stocks  Cost of Revenue  Current Ratio  \\\n",
       "1107            -802000000.0   6.730600e+10     2.038500e+10          271.0   \n",
       "1108            -161000000.0   6.836600e+10     2.707800e+10          250.0   \n",
       "1109            -272000000.0   6.846500e+10     3.303800e+10          247.0   \n",
       "1110             600000000.0   6.817800e+10     3.278000e+10          235.0   \n",
       "\n",
       "      Deferred Asset Charges  Deferred Liability Charges  Depreciation  \\\n",
       "1107                     0.0                3.469000e+09  3.755000e+09   \n",
       "1108                     0.0                4.736000e+09  5.212000e+09   \n",
       "1109                     0.0                3.390000e+09  5.957000e+09   \n",
       "1110                     0.0                7.917000e+09  6.622000e+09   \n",
       "\n",
       "      Earnings Before Interest and Tax  Earnings Before Tax  \\\n",
       "1107                      2.705200e+10         2.705200e+10   \n",
       "1108                      2.782000e+10         2.782000e+10   \n",
       "1109                      1.850700e+10         1.850700e+10   \n",
       "1110                      1.975100e+10         1.975100e+10   \n",
       "\n",
       "      Effect of Exchange Rate  Equity Earnings/Loss Unconsolidated Subsidiary  \\\n",
       "1107               -8000000.0                                             0.0   \n",
       "1108             -139000000.0                                             0.0   \n",
       "1109              -73000000.0                                             0.0   \n",
       "1110              -67000000.0                                             0.0   \n",
       "\n",
       "      Fixed Assets      Goodwill  Gross Margin  Gross Profit    Income Tax  \\\n",
       "1107  9.991000e+09  1.465500e+10          74.0  5.746400e+10  5.189000e+09   \n",
       "1108  1.301100e+10  2.012700e+10          69.0  5.975500e+10  5.746000e+09   \n",
       "1109  1.473100e+10  1.693900e+10          65.0  6.054200e+10  6.314000e+09   \n",
       "1110  1.835600e+10  1.787200e+10          62.0  5.254000e+10  2.953000e+09   \n",
       "\n",
       "      Intangible Assets  Interest Expense     Inventory   Investments  \\\n",
       "1107       3.083000e+09               0.0  1.938000e+09 -1.780200e+10   \n",
       "1108       6.981000e+09               0.0  2.660000e+09 -7.324000e+09   \n",
       "1109       4.835000e+09               0.0  2.902000e+09 -1.286800e+10   \n",
       "1110       3.733000e+09               0.0  2.251000e+09 -1.441700e+10   \n",
       "\n",
       "       Liabilities  Long-Term Debt  Long-Term Investments  Minority Interest  \\\n",
       "1107  1.841000e+09    1.260100e+10           1.084400e+10                0.0   \n",
       "1108  2.562000e+09    2.064500e+10           1.459700e+10                0.0   \n",
       "1109 -7.900000e+07    2.780800e+10           1.205300e+10                0.0   \n",
       "1110 -9.380000e+08    4.078300e+10           1.043100e+10                0.0   \n",
       "\n",
       "      Misc. Stocks  Net Borrowings  Net Cash Flow  Net Cash Flow-Operating  \\\n",
       "1107           0.0    3.537000e+09  -3.134000e+09             2.883300e+10   \n",
       "1108           0.0    6.962000e+09   4.865000e+09             3.250200e+10   \n",
       "1109           0.0    1.366100e+10  -3.074000e+09             2.966800e+10   \n",
       "1110           0.0    1.828300e+10   9.150000e+08             3.332500e+10   \n",
       "\n",
       "      Net Cash Flows-Financing  Net Cash Flows-Investing    Net Income  \\\n",
       "1107             -8.148000e+09             -2.381100e+10  2.186300e+10   \n",
       "1108             -8.665000e+09             -1.883300e+10  2.207400e+10   \n",
       "1109             -9.668000e+09             -2.300100e+10  1.219300e+10   \n",
       "1110             -8.393000e+09             -2.395000e+10  1.679800e+10   \n",
       "\n",
       "      Net Income Adjustments  Net Income Applicable to Common Shareholders  \\\n",
       "1107            4.590000e+09                                  2.186300e+10   \n",
       "1108            4.592000e+09                                  2.207400e+10   \n",
       "1109            1.000500e+10                                  1.219300e+10   \n",
       "1110            1.198100e+10                                  1.679800e+10   \n",
       "\n",
       "      Net Income-Cont. Operations  Net Receivables  Non-Recurring Items  \\\n",
       "1107                 2.186300e+10     1.911800e+10         0.000000e+00   \n",
       "1108                 2.207400e+10     2.148500e+10         1.270000e+08   \n",
       "1109                 1.219300e+10     1.790800e+10         1.001100e+10   \n",
       "1110                 1.679800e+10     1.827700e+10         1.110000e+09   \n",
       "\n",
       "      Operating Income  Operating Margin  Other Assets  Other Current Assets  \\\n",
       "1107      2.676400e+10              34.0  2.392000e+09          3.388000e+09   \n",
       "1108      2.775900e+10              32.0  3.422000e+09          4.392000e+09   \n",
       "1109      1.816100e+10              19.0  3.117000e+09          5.461000e+09   \n",
       "1110      2.018200e+10              24.0  3.642000e+09          5.892000e+09   \n",
       "\n",
       "      Other Current Liabilities  Other Equity  Other Financing Activities  \\\n",
       "1107               2.423600e+10  1.743000e+09                 -10000000.0   \n",
       "1108               3.005600e+10  3.708000e+09                 -39000000.0   \n",
       "1109               2.977800e+10  2.522000e+09                 362000000.0   \n",
       "1110               3.341700e+10  1.537000e+09                -369000000.0   \n",
       "\n",
       "      Other Investing Activities  Other Liabilities  \\\n",
       "1107               -1.752000e+09       1.000000e+10   \n",
       "1108               -6.024000e+09       1.159400e+10   \n",
       "1109               -4.189000e+09       1.354400e+10   \n",
       "1110               -1.190000e+09       1.364000e+10   \n",
       "\n",
       "      Other Operating Activities  Other Operating Items  Pre-Tax Margin  \\\n",
       "1107               -6.070000e+08                    0.0            35.0   \n",
       "1108               -6.570000e+08                    0.0            32.0   \n",
       "1109                4.080000e+08                    0.0            20.0   \n",
       "1110               -1.208000e+09                    0.0            23.0   \n",
       "\n",
       "      Pre-Tax ROE  Profit Margin  Quick Ratio  Research and Development  \\\n",
       "1107         34.0           28.0        266.0              1.041100e+10   \n",
       "1108         31.0           25.0        245.0              1.138100e+10   \n",
       "1109         23.0           13.0        241.0              1.204600e+10   \n",
       "1110         27.0           20.0        231.0              1.198800e+10   \n",
       "\n",
       "      Retained Earnings  Sale and Purchase of Stock  \\\n",
       "1107       9.895000e+09               -4.429000e+09   \n",
       "1108       1.771000e+10               -6.709000e+09   \n",
       "1109       9.096000e+09               -1.380900e+10   \n",
       "1110       2.282000e+09               -1.530100e+10   \n",
       "\n",
       "      Sales, General and Admin.  \\\n",
       "1107               2.028900e+10   \n",
       "1108               2.048800e+10   \n",
       "1109               2.032400e+10   \n",
       "1110               1.926000e+10   \n",
       "\n",
       "      Short-Term Debt / Current Portion of Long-Term Debt  \\\n",
       "1107                                       2.999000e+09     \n",
       "1108                                       2.000000e+09     \n",
       "1109                                       7.484000e+09     \n",
       "1110                                       1.290400e+10     \n",
       "\n",
       "      Short-Term Investments  Total Assets  Total Current Assets  \\\n",
       "1107            7.321800e+10  1.424310e+11          1.014660e+11   \n",
       "1108            7.704000e+10  1.723840e+11          1.142460e+11   \n",
       "1109            9.093100e+10  1.744720e+11          1.227970e+11   \n",
       "1110            1.067300e+11  1.936940e+11          1.396600e+11   \n",
       "\n",
       "      Total Current Liabilities  Total Equity  Total Liabilities  \\\n",
       "1107               3.741700e+10  7.894400e+10       6.348700e+10   \n",
       "1108               4.562500e+10  8.978400e+10       8.260000e+10   \n",
       "1109               4.964700e+10  8.008300e+10       9.438900e+10   \n",
       "1110               5.935700e+10  7.199700e+10       1.216970e+11   \n",
       "\n",
       "      Total Liabilities & Equity  Total Revenue  Treasury Stock  For Year  \\\n",
       "1107                1.424310e+11   7.784900e+10             0.0    2013.0   \n",
       "1108                1.723840e+11   8.683300e+10             0.0    2014.0   \n",
       "1109                1.744720e+11   9.358000e+10             0.0    2015.0   \n",
       "1110                1.936940e+11   8.532000e+10             0.0    2016.0   \n",
       "\n",
       "      Earnings Per Share  Estimated Shares Outstanding  \n",
       "1107                2.61                  8.376628e+09  \n",
       "1108                2.66                  8.298496e+09  \n",
       "1109                1.49                  8.183221e+09  \n",
       "1110                2.12                  7.923585e+09  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", 80)\n",
    "fundamentals[fundamentals[\"Ticker Symbol\"] == \"MSFT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dental-waterproof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>Address of Headquarters</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corp.</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Systems Software</td>\n",
       "      <td>Redmond, Washington</td>\n",
       "      <td>1994-06-01</td>\n",
       "      <td>789019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ticker symbol         Security SEC filings             GICS Sector  \\\n",
       "306          MSFT  Microsoft Corp.     reports  Information Technology   \n",
       "\n",
       "    GICS Sub Industry Address of Headquarters Date first added     CIK  \n",
       "306  Systems Software     Redmond, Washington       1994-06-01  789019  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "securities[securities[\"Ticker symbol\"] == \"MSFT\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ancient-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique companies in the dataset:  501\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique companies in the dataset: { len(prices['symbol'].unique()) : >4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-chester",
   "metadata": {},
   "source": [
    "# Selected stock indicators\n",
    "____\n",
    "* __On-Balance Volume__ *(OBV)*  \n",
    "Indicator of stock momentum based on close price and stock volume\n",
    "____\n",
    "* __Accumulation/Distribution Index__ *(ADI)*  \n",
    "money flow indicator considers stock volume as well as closing price in regard to price range.\n",
    "____\n",
    "* __Aroon Indicator__ *(AI / AIU / AID)*  \n",
    "Trend following indicator, describes strength of the current trend and likely hood that it will continue.  \n",
    "May be divided into up and down indexes.\n",
    "____\n",
    "* __Relative Strength Index__ *(RSI)*  \n",
    "Measurement of the of price change magnitude, indicates overbought or oversold conditions in the price of a stock.\n",
    "____\n",
    "* __Volume Weighted Average Price__ *(VWAP)*\n",
    "Average price calculated in regard to stock volume.\n",
    "____\n",
    "* __Simple Moving Average 7 Days__ *(SMA7)*  \n",
    "Moving average over 7 day period\n",
    "____\n",
    "* __Simple Moving Average 14 Days__ *(SMA14)*  \n",
    "Moving average over 14 day period\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "moderate-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = prices[prices[\"symbol\"] == \"MSFT\"]\n",
    "for symbol in prices['symbol'].unique()[:7]:\n",
    "    stock_price = stock_price.append(prices[prices[\"symbol\"] == symbol], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.area(stock_price, x=\"date\", y=\"close\", color=\"symbol\",\n",
    "              animation_group=\"close\", animation_frame=\"symbol\", \n",
    "              hover_data={\"date\": \"|%d.%m.%Y\"}, \n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              title = \"Closing prices\",\n",
    "              template=\"plotly_white\",\n",
    "              range_y = [stock_price.close.min(), stock_price.close.max()],\n",
    "              labels={\"close\": \"close price\"}\n",
    "            )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.95,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    ),\n",
    "    updatemenus=[dict(buttons=[dict(visible=False)])],\n",
    "    sliders=[dict(x=0, len=1)],\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_yaxes(tickprefix=\"$\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price[\"OBV\"] = ta.volume.on_balance_volume(stock_price[\"close\"],\n",
    "                                                   stock_price[\"volume\"])\n",
    "fig = px.area(stock_price, x=\"date\", y=\"OBV\", color=\"symbol\",\n",
    "              facet_col=\"symbol\", facet_col_wrap=2, height=600, \n",
    "              hover_data={\"date\": \"|%d.%m.%Y\"}, template=\"plotly_white\",\n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              title = \"On Balance Voulme\",\n",
    "              labels={\"OBV\": \"OBV [-]\"}\n",
    "            )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.95,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = ta.volume.AccDistIndexIndicator(stock_price[\"high\"], stock_price[\"low\"],\n",
    "                                            stock_price[\"close\"], stock_price[\"volume\"])\n",
    "stock_price[\"ADI\"] = indicator.acc_dist_index()\n",
    "fig = px.area(stock_price, x=\"date\", y=\"ADI\", color=\"symbol\",\n",
    "              facet_col=\"symbol\", facet_col_wrap=2, height=600, \n",
    "              hover_data={\"date\": \"|%d.%m.%Y\"}, template=\"plotly_white\",\n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              title=\"Accumulation & Distribution Index\",\n",
    "              labels={\"ADI\": \"ADI [-]\"}\n",
    "            )\n",
    "          \n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.95,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = ta.trend.AroonIndicator(stock_price[\"close\"])\n",
    "stock_price[\"AI\"] = indicator.aroon_indicator()\n",
    "stock_price[\"AIU\"] = indicator.aroon_up()\n",
    "stock_price[\"AID\"] = indicator.aroon_down()\n",
    "\n",
    "fig = px.area(stock_price, x=\"date\", y=\"AI\", color=\"symbol\",\n",
    "              animation_group=\"AI\", animation_frame=\"symbol\", \n",
    "              hover_data={\"date\": \"|%d.%m.%Y\"}, template=\"simple_white\",\n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              title = \"Accumulation & Distribution Index\",\n",
    "              labels = {\"AI\": \"Accumulation & Distribution Index\"}\n",
    "            )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.95,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    ),\n",
    "    updatemenus=[dict(buttons=[dict(visible=False)])],\n",
    "    sliders=[dict(x=0, len=1)],\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = ta.momentum.RSIIndicator(close=stock_price[\"close\"], window=14)\n",
    "stock_price[\"RSI\"] = indicator.rsi()\n",
    "\n",
    "fig = px.area(stock_price, x=\"date\", y=\"RSI\", color=\"symbol\",\n",
    "              animation_group=\"RSI\", animation_frame=\"symbol\", \n",
    "              hover_data={\"date\": \"|%d.%m.%Y\"}, template=\"simple_white\",\n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              title=\"Relative Strength Index\",\n",
    "              labels={\"RSI\": \"Relative Strength Index\"},\n",
    "              range_y = [0, 100]\n",
    "            )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.95,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    ),\n",
    "    updatemenus=[dict(buttons=[dict(visible=False)])],\n",
    "    sliders=[dict(x=0, len=1)],\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = ta.volume.VolumeWeightedAveragePrice(stock_price[\"high\"], stock_price[\"low\"], \n",
    "                                     stock_price[\"close\"],stock_price[\"volume\"], window=14)\n",
    "\n",
    "stock_price[\"VWAP\"] = indicator.volume_weighted_average_price()\n",
    "\n",
    "indicator = ta.trend.SMAIndicator(stock_price[\"close\"], window=7)\n",
    "stock_price[\"SMA7\"] = indicator.sma_indicator()\n",
    "\n",
    "indicator = ta.trend.SMAIndicator(stock_price[\"close\"], window=14)\n",
    "stock_price[\"SMA14\"] = indicator.sma_indicator()\n",
    "\n",
    "fig = px.area(stock_price, x=\"date\", y=\"VWAP\", color=\"symbol\",\n",
    "              animation_group=\"VWAP\", animation_frame=\"symbol\", \n",
    "              hover_data={\"date\": \"|%d.%m.%Y\"}, template=\"simple_white\",\n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              title=\"Volume Weighted Average Price\",\n",
    "              labels={\"VWAP\": \"Volume Weighted Average Price\"},\n",
    "              range_y = [stock_price.VWAP.min(), stock_price.VWAP.max()]\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.95,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    ),\n",
    "    updatemenus=[dict(buttons=[dict(visible=False)])],\n",
    "    sliders=[dict(x=0, len=1)],\n",
    "    showlegend=False\n",
    ")\n",
    "fig.update_yaxes(ticksuffix=\"%\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "special-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBV</th>\n",
       "      <th>ADI</th>\n",
       "      <th>AI</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>RSI</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-217647100.0</td>\n",
       "      <td>-1.845589e+08</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>28.918897</td>\n",
       "      <td>28.882689</td>\n",
       "      <td>27.719999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-158451300.0</td>\n",
       "      <td>-1.915822e+08</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>28.792828</td>\n",
       "      <td>33.642631</td>\n",
       "      <td>28.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-207042600.0</td>\n",
       "      <td>-2.037300e+08</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>28.665757</td>\n",
       "      <td>33.476222</td>\n",
       "      <td>27.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-141048900.0</td>\n",
       "      <td>-1.905311e+08</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>28.567642</td>\n",
       "      <td>35.702520</td>\n",
       "      <td>28.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-222166100.0</td>\n",
       "      <td>-1.533522e+08</td>\n",
       "      <td>-56.0</td>\n",
       "      <td>28.470470</td>\n",
       "      <td>33.916011</td>\n",
       "      <td>27.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            OBV           ADI    AI       VWAP        RSI      close\n",
       "24 -217647100.0 -1.845589e+08 -56.0  28.918897  28.882689  27.719999\n",
       "25 -158451300.0 -1.915822e+08 -56.0  28.792828  33.642631  28.010000\n",
       "26 -207042600.0 -2.037300e+08 -56.0  28.665757  33.476222  27.990000\n",
       "27 -141048900.0 -1.905311e+08 -56.0  28.567642  35.702520  28.120001\n",
       "28 -222166100.0 -1.533522e+08 -56.0  28.470470  33.916011  27.930000"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_company = stock_price[\"symbol\"] == \"MSFT\"\n",
    "indicators = pd.DataFrame()\n",
    "\n",
    "indicators[\"OBV\"] = stock_price[\"OBV\"][single_company]\n",
    "indicators[\"ADI\"] = stock_price[\"ADI\"][single_company]\n",
    "indicators[\"AI\"] = stock_price[\"AI\"][single_company]\n",
    "# indicators[\"AID\"] = stock_price[\"AID\"][single_company]\n",
    "# indicators[\"AIU\"] = stock_price[\"AIU\"][single_company]\n",
    "indicators[\"VWAP\"] = stock_price[\"VWAP\"][single_company]\n",
    "indicators[\"RSI\"] = stock_price[\"RSI\"][single_company]\n",
    "# indicators[\"SMA7\"] = stock_price[\"SMA7\"][single_company]\n",
    "# indicators[\"SMA14\"] = stock_price[\"SMA14\"][single_company]\n",
    "indicators[\"close\"] = stock_price[\"close\"][single_company]\n",
    "\n",
    "indicators = indicators.dropna()\n",
    "indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "optical-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBV</th>\n",
       "      <th>ADI</th>\n",
       "      <th>AI</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>RSI</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821259</td>\n",
       "      <td>0.147287</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.127246</td>\n",
       "      <td>0.163888</td>\n",
       "      <td>0.115981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.839087</td>\n",
       "      <td>0.145149</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.124011</td>\n",
       "      <td>0.235852</td>\n",
       "      <td>0.123122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.141451</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.120751</td>\n",
       "      <td>0.233336</td>\n",
       "      <td>0.122630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.844328</td>\n",
       "      <td>0.145469</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>0.266995</td>\n",
       "      <td>0.125831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.819898</td>\n",
       "      <td>0.156788</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.115741</td>\n",
       "      <td>0.239985</td>\n",
       "      <td>0.121152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        OBV       ADI        AI      VWAP       RSI     close\n",
       "0  0.821259  0.147287  0.208333  0.127246  0.163888  0.115981\n",
       "1  0.839087  0.145149  0.208333  0.124011  0.235852  0.123122\n",
       "2  0.824453  0.141451  0.208333  0.120751  0.233336  0.122630\n",
       "3  0.844328  0.145469  0.208333  0.118234  0.266995  0.125831\n",
       "4  0.819898  0.156788  0.208333  0.115741  0.239985  0.121152"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "transformer = MinMaxScaler().fit(indicators)\n",
    "scaled_indicators = pd.DataFrame(transformer.transform(indicators), columns=indicators.columns)\n",
    "scaled_indicators.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "willing-partner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_x: (1202, 14, 6)\n",
      "Train_y: (1202, 1)\n",
      "---------------------------------\n",
      "Val_x:   (331, 14, 6)\n",
      "Val_y:   (331, 1)\n",
      "---------------------------------\n",
      "Test_x:  (158, 14, 6)\n",
      "Test_y:  (158, 1)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 14\n",
    "predicted_values = [\"close\"]\n",
    "\n",
    "train_data_length = (0, round(0.7 * scaled_indicators.shape[0]))\n",
    "val_data_length = (round(0.7 * scaled_indicators.shape[0])+1, round(0.9 * scaled_indicators.shape[0]))\n",
    "test_data_length = (round(0.9 * scaled_indicators.shape[0])+1, scaled_indicators.shape[0])\n",
    "\n",
    "train_x = generate_input_sequences(data=scaled_indicators[train_data_length[0]:train_data_length[1]],\n",
    "                                   input_length=sequence_length)\n",
    "train_y = generate_output_sequences(data=scaled_indicators[train_data_length[0]:train_data_length[1]],\n",
    "                                    input_length=sequence_length, outputs=predicted_values)\n",
    "\n",
    "val_x = generate_input_sequences(data=scaled_indicators[val_data_length[0]:val_data_length[1]],\n",
    "                                 input_length=sequence_length)\n",
    "val_y = generate_output_sequences(data=scaled_indicators[val_data_length[0]:val_data_length[1]],\n",
    "                                  input_length=sequence_length, outputs=predicted_values)\n",
    "\n",
    "test_x = generate_input_sequences(data=scaled_indicators[test_data_length[0]:test_data_length[1]],\n",
    "                                  input_length=sequence_length)\n",
    "test_y = generate_output_sequences(data=scaled_indicators[test_data_length[0]:test_data_length[1]],\n",
    "                                   input_length=sequence_length, outputs=predicted_values)\n",
    "\n",
    "print(f\"Train_x: {train_x.shape}\")\n",
    "print(f\"Train_y: {train_y.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Val_x:   {val_x.shape}\")\n",
    "print(f\"Val_y:   {val_y.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Test_x:  {test_x.shape}\")\n",
    "print(f\"Test_y:  {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "photographic-circular",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"first_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (LSTM)                (None, 14, 50)            11400     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1202 samples, validate on 331 samples\n",
      "Epoch 1/40\n",
      "1202/1202 [==============================] - 2s 1ms/step - loss: 0.0987 - mean_absolute_percentage_error: 61677.1523 - val_loss: 0.0769 - val_mean_absolute_percentage_error: 11.8594\n",
      "Epoch 2/40\n",
      "1202/1202 [==============================] - 1s 780us/step - loss: 0.0444 - mean_absolute_percentage_error: 27256.7344 - val_loss: 0.0776 - val_mean_absolute_percentage_error: 12.0401\n",
      "Epoch 3/40\n",
      "1202/1202 [==============================] - 1s 799us/step - loss: 0.0355 - mean_absolute_percentage_error: 47953.7852 - val_loss: 0.0730 - val_mean_absolute_percentage_error: 11.4367\n",
      "Epoch 4/40\n",
      "1202/1202 [==============================] - 1s 861us/step - loss: 0.0344 - mean_absolute_percentage_error: 57087.6992 - val_loss: 0.0643 - val_mean_absolute_percentage_error: 10.0240\n",
      "Epoch 5/40\n",
      "1202/1202 [==============================] - 1s 841us/step - loss: 0.0308 - mean_absolute_percentage_error: 55209.4766 - val_loss: 0.0656 - val_mean_absolute_percentage_error: 10.0771\n",
      "Epoch 6/40\n",
      "1202/1202 [==============================] - 1s 801us/step - loss: 0.0283 - mean_absolute_percentage_error: 31844.4102 - val_loss: 0.0731 - val_mean_absolute_percentage_error: 11.2422\n",
      "Epoch 7/40\n",
      "1202/1202 [==============================] - 1s 808us/step - loss: 0.0283 - mean_absolute_percentage_error: 37548.7617 - val_loss: 0.0471 - val_mean_absolute_percentage_error: 7.1942\n",
      "Epoch 8/40\n",
      "1202/1202 [==============================] - 1s 772us/step - loss: 0.0269 - mean_absolute_percentage_error: 41196.7539 - val_loss: 0.0727 - val_mean_absolute_percentage_error: 11.1130\n",
      "Epoch 9/40\n",
      "1202/1202 [==============================] - 1s 756us/step - loss: 0.0253 - mean_absolute_percentage_error: 36780.4141 - val_loss: 0.0676 - val_mean_absolute_percentage_error: 10.3887\n",
      "Epoch 10/40\n",
      "1202/1202 [==============================] - 1s 752us/step - loss: 0.0241 - mean_absolute_percentage_error: 49478.6094 - val_loss: 0.0460 - val_mean_absolute_percentage_error: 6.9538\n",
      "Epoch 11/40\n",
      "1202/1202 [==============================] - 1s 781us/step - loss: 0.0238 - mean_absolute_percentage_error: 48084.1758 - val_loss: 0.0355 - val_mean_absolute_percentage_error: 5.5421\n",
      "Epoch 12/40\n",
      "1202/1202 [==============================] - 1s 789us/step - loss: 0.0244 - mean_absolute_percentage_error: 40069.6211 - val_loss: 0.0456 - val_mean_absolute_percentage_error: 6.8738\n",
      "Epoch 13/40\n",
      "1202/1202 [==============================] - 1s 729us/step - loss: 0.0232 - mean_absolute_percentage_error: 60516.3203 - val_loss: 0.0718 - val_mean_absolute_percentage_error: 10.8863\n",
      "Epoch 14/40\n",
      "1202/1202 [==============================] - 1s 759us/step - loss: 0.0223 - mean_absolute_percentage_error: 45028.5898 - val_loss: 0.0448 - val_mean_absolute_percentage_error: 6.7540\n",
      "Epoch 15/40\n",
      "1202/1202 [==============================] - 1s 749us/step - loss: 0.0233 - mean_absolute_percentage_error: 49150.0195 - val_loss: 0.1020 - val_mean_absolute_percentage_error: 15.8733\n",
      "Epoch 16/40\n",
      "1202/1202 [==============================] - 1s 726us/step - loss: 0.0265 - mean_absolute_percentage_error: 28393.9941 - val_loss: 0.0803 - val_mean_absolute_percentage_error: 12.3958\n",
      "Epoch 17/40\n",
      "1202/1202 [==============================] - 1s 723us/step - loss: 0.0228 - mean_absolute_percentage_error: 52640.3438 - val_loss: 0.0994 - val_mean_absolute_percentage_error: 15.4578\n",
      "Epoch 18/40\n",
      "1202/1202 [==============================] - 1s 773us/step - loss: 0.0240 - mean_absolute_percentage_error: 40386.9336 - val_loss: 0.0510 - val_mean_absolute_percentage_error: 7.7698\n",
      "Epoch 19/40\n",
      "1202/1202 [==============================] - 1s 709us/step - loss: 0.0222 - mean_absolute_percentage_error: 45698.6406 - val_loss: 0.0413 - val_mean_absolute_percentage_error: 6.3023\n",
      "Epoch 20/40\n",
      "1202/1202 [==============================] - 1s 785us/step - loss: 0.0221 - mean_absolute_percentage_error: 40678.5312 - val_loss: 0.0654 - val_mean_absolute_percentage_error: 10.0187\n",
      "Epoch 21/40\n",
      "1202/1202 [==============================] - 1s 759us/step - loss: 0.0211 - mean_absolute_percentage_error: 57015.7422 - val_loss: 0.0969 - val_mean_absolute_percentage_error: 15.1368\n",
      "Epoch 22/40\n",
      "1202/1202 [==============================] - 1s 785us/step - loss: 0.0226 - mean_absolute_percentage_error: 43900.1289 - val_loss: 0.0632 - val_mean_absolute_percentage_error: 9.5769\n",
      "Epoch 23/40\n",
      "1202/1202 [==============================] - 1s 794us/step - loss: 0.0196 - mean_absolute_percentage_error: 41276.2891 - val_loss: 0.0796 - val_mean_absolute_percentage_error: 12.3738\n",
      "Epoch 24/40\n",
      "1202/1202 [==============================] - 1s 771us/step - loss: 0.0201 - mean_absolute_percentage_error: 39976.6875 - val_loss: 0.0706 - val_mean_absolute_percentage_error: 10.8187\n",
      "Epoch 25/40\n",
      "1202/1202 [==============================] - 1s 784us/step - loss: 0.0202 - mean_absolute_percentage_error: 44242.8789 - val_loss: 0.0636 - val_mean_absolute_percentage_error: 9.6991\n",
      "Epoch 26/40\n",
      "1202/1202 [==============================] - 1s 804us/step - loss: 0.0207 - mean_absolute_percentage_error: 45170.7734 - val_loss: 0.0369 - val_mean_absolute_percentage_error: 5.6763\n",
      "Epoch 27/40\n",
      "1202/1202 [==============================] - 1s 738us/step - loss: 0.0218 - mean_absolute_percentage_error: 41830.7461 - val_loss: 0.0685 - val_mean_absolute_percentage_error: 10.5378\n",
      "Epoch 28/40\n",
      "1202/1202 [==============================] - 1s 781us/step - loss: 0.0217 - mean_absolute_percentage_error: 36781.8711 - val_loss: 0.0885 - val_mean_absolute_percentage_error: 13.7750\n",
      "Epoch 29/40\n",
      "1202/1202 [==============================] - 1s 793us/step - loss: 0.0204 - mean_absolute_percentage_error: 53263.5898 - val_loss: 0.0866 - val_mean_absolute_percentage_error: 13.4034\n",
      "Epoch 30/40\n",
      "1202/1202 [==============================] - 1s 804us/step - loss: 0.0220 - mean_absolute_percentage_error: 49177.1016 - val_loss: 0.0805 - val_mean_absolute_percentage_error: 12.4153\n",
      "Epoch 31/40\n",
      "1202/1202 [==============================] - 1s 810us/step - loss: 0.0188 - mean_absolute_percentage_error: 41137.4961 - val_loss: 0.0656 - val_mean_absolute_percentage_error: 10.0254\n",
      "Epoch 32/40\n",
      "1202/1202 [==============================] - 1s 734us/step - loss: 0.0195 - mean_absolute_percentage_error: 28984.7031 - val_loss: 0.0442 - val_mean_absolute_percentage_error: 6.6821\n",
      "Epoch 33/40\n",
      "1202/1202 [==============================] - 1s 748us/step - loss: 0.0192 - mean_absolute_percentage_error: 40946.4141 - val_loss: 0.0865 - val_mean_absolute_percentage_error: 13.4782\n",
      "Epoch 34/40\n",
      "1202/1202 [==============================] - 1s 774us/step - loss: 0.0195 - mean_absolute_percentage_error: 34659.7969 - val_loss: 0.0473 - val_mean_absolute_percentage_error: 7.1277\n",
      "Epoch 35/40\n",
      "1202/1202 [==============================] - 1s 739us/step - loss: 0.0202 - mean_absolute_percentage_error: 44504.2031 - val_loss: 0.0631 - val_mean_absolute_percentage_error: 9.6792\n",
      "Epoch 36/40\n",
      "1202/1202 [==============================] - 1s 732us/step - loss: 0.0191 - mean_absolute_percentage_error: 41117.6406 - val_loss: 0.0747 - val_mean_absolute_percentage_error: 11.5586\n",
      "Epoch 37/40\n",
      "1202/1202 [==============================] - 1s 759us/step - loss: 0.0195 - mean_absolute_percentage_error: 26933.5898 - val_loss: 0.0708 - val_mean_absolute_percentage_error: 10.9443\n",
      "Epoch 38/40\n",
      "1202/1202 [==============================] - 1s 761us/step - loss: 0.0186 - mean_absolute_percentage_error: 41481.0547 - val_loss: 0.0750 - val_mean_absolute_percentage_error: 11.6580\n",
      "Epoch 39/40\n",
      "1202/1202 [==============================] - 1s 753us/step - loss: 0.0185 - mean_absolute_percentage_error: 35514.9258 - val_loss: 0.0769 - val_mean_absolute_percentage_error: 11.9897\n",
      "Epoch 40/40\n",
      "1202/1202 [==============================] - 1s 724us/step - loss: 0.0191 - mean_absolute_percentage_error: 36001.1875 - val_loss: 0.0671 - val_mean_absolute_percentage_error: 10.4035\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "batch_size = 64\n",
    "\n",
    "model_name = \"first_model\"\n",
    "\n",
    "model = models.Sequential(name=model_name)\n",
    "\n",
    "model.add(layers.LSTM(units=50, activation=\"relu\", name=\"LSTM_1\", dropout=0.05, \n",
    "                      input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "                      return_sequences=True))\n",
    "\n",
    "model.add(layers.LSTM(units=100, activation=\"relu\", name=\"LSTM_2\", dropout=0.1))\n",
    "\n",
    "model.add(layers.Dense(units=200, activation=\"relu\", name=\"Dense_1\"))\n",
    "model.add(layers.Dropout(0.15, name=\"Dropout_1\"))\n",
    "\n",
    "model.add(layers.Dense(units=400, activation=\"relu\", name=\"Dense_2\"))\n",
    "model.add(layers.Dropout(0.25, name=\"Dropout_2\"))\n",
    "\n",
    "model.add(layers.Dense(units=50, activation=\"relu\", name=\"Dense_3\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation=\"tanh\", name=\"classifier\"))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", \n",
    "              loss=\"mae\", \n",
    "              metrics=[\"mean_absolute_percentage_error\"])\n",
    "model.summary()\n",
    "\n",
    "history =  model.fit(train_x, train_y,\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size, \n",
    "                     validation_data=(val_x, val_y))\n",
    "\n",
    "\n",
    "model_save_name = next_free_model_name(model_name)\n",
    "model_save_path = MODELS_DIR + \"/\" + model_save_name + \".h5\"\n",
    "model.save(model_save_path)\n",
    "\n",
    "history_save_path = MODELS_DIR + \"/\" + model_save_name + \".csv\"\n",
    "history_dataframe = pd.DataFrame(history.history)\n",
    "history_dataframe.to_csv(history_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_history = pd.read_csv(MODELS_DIR + \"/\" + \"first_model_000.csv\", index_col=0)\n",
    "plot_losses(loaded_history)\n",
    "\n",
    "model = keras.models.load_model(MODELS_DIR + \"/\" + \"first_model_000.h5\")\n",
    "predictions = model.predict(test_x)\n",
    "scaler = MinMaxScaler().fit(indicators[\"close\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results[\"guesses\"] = scaler.inverse_transform(predictions)[:,0]\n",
    "results[\"verification\"] = scaler.inverse_transform(test_y)[:,0]\n",
    "results[\"x\"] = np.arange(results.shape[0])\n",
    "\n",
    "fig = px.line(results, x=\"x\", y=[\"guesses\", \"verification\"], \n",
    "              color_discrete_sequence=px.colors.qualitative.G10,\n",
    "              labels = {\"y\": \"close price\", \"x\": \"test sample number\"},\n",
    "              template=\"plotly_white\",\n",
    "              title=\"Results Verification\"\n",
    "            )\n",
    "fig.update_layout(\n",
    "    title = dict(\n",
    "        y = 0.9,\n",
    "        x = 0.5,\n",
    "        xanchor = \"center\",\n",
    "        yanchor = \"top\",\n",
    "    ),\n",
    ")\n",
    "fig.update_yaxes(tickprefix=\"$\", title=\"closing price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-theater",
   "metadata": {},
   "source": [
    "## Expanding training data using multiple companies\n",
    "Data of all companies is stored in 3D tensor where 3rd dimension represents different company.  \n",
    "Data is scaled to range (-1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "logical-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_to_process = 100\n",
    "tickers = prices.symbol.unique()[:companies_to_process]\n",
    "\n",
    "company_data = []\n",
    "for ticker in tickers:\n",
    "    stock_price = prices[prices[\"symbol\"] == ticker]\n",
    "    new_indicators = pd.DataFrame()\n",
    "    \n",
    "    new_indicators[\"OBV\"] = ta.volume.on_balance_volume(stock_price[\"close\"], stock_price[\"volume\"])\n",
    "    \n",
    "    indicator = ta.volume.AccDistIndexIndicator(stock_price[\"high\"], stock_price[\"low\"],\n",
    "                                            stock_price[\"close\"], stock_price[\"volume\"])\n",
    "    new_indicators[\"ADI\"] = indicator.acc_dist_index()\n",
    "    \n",
    "    indicator = ta.trend.AroonIndicator(stock_price[\"close\"])\n",
    "    new_indicators[\"AI\"]  = indicator.aroon_indicator()\n",
    "    \n",
    "    indicator = ta.momentum.RSIIndicator(close=stock_price[\"close\"], window=14)\n",
    "    new_indicators[\"RSI\"] = indicator.rsi()\n",
    "    \n",
    "    indicator = ta.volume.VolumeWeightedAveragePrice(stock_price[\"high\"], stock_price[\"low\"], \n",
    "                                     stock_price[\"close\"],stock_price[\"volume\"], window=14)\n",
    "    new_indicators[\"VWAP\"] = indicator.volume_weighted_average_price()\n",
    "    \n",
    "    new_indicators[\"close\"] = stock_price[\"close\"]\n",
    "    new_indicators = new_indicators.to_numpy()\n",
    "    \n",
    "    company_data.append(new_indicators)\n",
    "\n",
    "company_data = np.array(company_data, dtype=object)\n",
    "price_data=company_data\n",
    "\n",
    "new_price_data = []\n",
    "for company in price_data:\n",
    "    new_comapny = company[~np.isnan(company).any(axis=1)]\n",
    "    new_price_data.append(new_comapny)\n",
    "\n",
    "price_data = np.array(new_price_data, dtype=object)\n",
    "scaled_price_data, scalers = scale_3d_price_data(price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "educational-atlas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented train_x: (70,)\n",
      "Segmented rain_y: (70,)\n",
      "---------------------------------\n",
      "Segmented val_x:   (20, 1723, 14, 6)\n",
      "Segmented val_y:   (20, 1723, 1)\n",
      "---------------------------------\n",
      "Segmented test_x:  (10, 1723, 14, 6)\n",
      "Segmented test_y:  (10, 1723, 1)\n",
      "---------------------------------\n",
      "Train_x:  (119099, 14, 6)\n",
      "Train_y:  (119099, 1)\n",
      "---------------------------------\n",
      "Val_x:   (34460, 14, 6)\n",
      "Val_y:   (34460, 1)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 14\n",
    "predicted_values = -1 # last value in \n",
    "data_split = (0.7, 0.2, 0.1)\n",
    "\n",
    "# price_data = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "train_data_length = (0, round(data_split[0] * scaled_price_data.shape[0]))\n",
    "val_data_length = (train_data_length[1], train_data_length[1] + round(data_split[1] * scaled_price_data.shape[0]))\n",
    "test_data_length = (val_data_length[1], val_data_length[1] + round(data_split[2] * scaled_price_data.shape[0]))\n",
    "\n",
    "input_data, output_data = [], []\n",
    "for company in scaled_price_data:\n",
    "    input_data.append(generate_input_sequences(data=company, input_length=sequence_length))\n",
    "    output_data.append(generate_output_sequences(data=company, input_length=sequence_length, \n",
    "                                                 outputs=predicted_values))\n",
    "\n",
    "train_x_segmented = np.array(input_data[train_data_length[0]:train_data_length[1]], dtype=object)\n",
    "train_y_segmented = np.array(output_data[train_data_length[0]:train_data_length[1]], dtype=object)\n",
    "train_scalers = scalers[train_data_length[0]:train_data_length[1]]\n",
    "train_tickers = tickers[train_data_length[0]:train_data_length[1]]\n",
    "\n",
    "val_x_segmented = np.array(input_data[val_data_length[0]:val_data_length[1]], dtype=object)\n",
    "val_y_segmented = np.array(output_data[val_data_length[0]:val_data_length[1]], dtype=object)\n",
    "val_scalers = scalers[val_data_length[0]:val_data_length[1]]\n",
    "val_tickers = tickers[val_data_length[0]:val_data_length[1]]\n",
    "\n",
    "test_x_segmented = np.array(input_data[test_data_length[0]:test_data_length[1]], dtype=object)\n",
    "test_y_segmented = np.array(output_data[test_data_length[0]:test_data_length[1]], dtype=object)\n",
    "test_scalers = scalers[test_data_length[0]:test_data_length[1]]\n",
    "test_tickers = tickers[test_data_length[0]:test_data_length[1]]\n",
    "train_x = flatten_data(train_x_segmented)\n",
    "train_y = flatten_data(train_y_segmented)\n",
    "\n",
    "val_x = flatten_data(val_x_segmented)\n",
    "val_y = flatten_data(val_y_segmented)\n",
    "\n",
    "print(f\"Segmented train_x: {train_x_segmented.shape}\")\n",
    "print(f\"Segmented rain_y: {train_y_segmented.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Segmented val_x:   {val_x_segmented.shape}\")\n",
    "print(f\"Segmented val_y:   {val_y_segmented.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Segmented test_x:  {test_x_segmented.shape}\")\n",
    "print(f\"Segmented test_y:  {test_y_segmented.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Train_x:  {train_x.shape}\")\n",
    "print(f\"Train_y:  {train_y.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Val_x:   {val_x.shape}\")\n",
    "print(f\"Val_y:   {val_y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "practical-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "distinguished-cream",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"second_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (LSTM)                (None, 14, 50)            11400     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 119099 samples, validate on 34460 samples\n",
      "Epoch 1/30\n",
      "119099/119099 [==============================] - 23s 193us/step - loss: 0.0432 - mean_absolute_percentage_error: 23804.0996 - val_loss: 0.0942 - val_mean_absolute_percentage_error: 15651.6348\n",
      "Epoch 2/30\n",
      "119099/119099 [==============================] - 23s 192us/step - loss: 0.0256 - mean_absolute_percentage_error: 18885.2773 - val_loss: 0.0990 - val_mean_absolute_percentage_error: 14489.5020\n",
      "Epoch 3/30\n",
      "119099/119099 [==============================] - 23s 193us/step - loss: 0.0229 - mean_absolute_percentage_error: 19905.5508 - val_loss: 0.0935 - val_mean_absolute_percentage_error: 11968.5605\n",
      "Epoch 4/30\n",
      "119099/119099 [==============================] - 21s 180us/step - loss: 0.0210 - mean_absolute_percentage_error: 17742.9961 - val_loss: 0.0994 - val_mean_absolute_percentage_error: 14099.3438\n",
      "Epoch 5/30\n",
      "119099/119099 [==============================] - 22s 183us/step - loss: 0.0201 - mean_absolute_percentage_error: 17937.3379 - val_loss: 0.1117 - val_mean_absolute_percentage_error: 12360.3652\n",
      "Epoch 6/30\n",
      "119099/119099 [==============================] - 23s 193us/step - loss: 0.0191 - mean_absolute_percentage_error: 14710.8467 - val_loss: 0.1108 - val_mean_absolute_percentage_error: 11812.9277\n",
      "Epoch 7/30\n",
      "119099/119099 [==============================] - 23s 190us/step - loss: 0.0184 - mean_absolute_percentage_error: 14265.6035 - val_loss: 0.1162 - val_mean_absolute_percentage_error: 15544.8633\n",
      "Epoch 8/30\n",
      "119099/119099 [==============================] - 22s 189us/step - loss: 0.0182 - mean_absolute_percentage_error: 17536.8008 - val_loss: 0.1145 - val_mean_absolute_percentage_error: 10371.1650\n",
      "Epoch 9/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0176 - mean_absolute_percentage_error: 17018.1992 - val_loss: 0.1044 - val_mean_absolute_percentage_error: 11945.1963\n",
      "Epoch 10/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0173 - mean_absolute_percentage_error: 13925.0186 - val_loss: 0.1079 - val_mean_absolute_percentage_error: 10685.1279\n",
      "Epoch 11/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0168 - mean_absolute_percentage_error: 13426.8428 - val_loss: 0.1115 - val_mean_absolute_percentage_error: 12970.3359\n",
      "Epoch 12/30\n",
      "119099/119099 [==============================] - 22s 188us/step - loss: 0.0165 - mean_absolute_percentage_error: 14192.1836 - val_loss: 0.1038 - val_mean_absolute_percentage_error: 14910.7500\n",
      "Epoch 13/30\n",
      "119099/119099 [==============================] - 22s 188us/step - loss: 0.0162 - mean_absolute_percentage_error: 12832.3086 - val_loss: 0.0982 - val_mean_absolute_percentage_error: 12916.8135\n",
      "Epoch 14/30\n",
      "119099/119099 [==============================] - 22s 183us/step - loss: 0.0158 - mean_absolute_percentage_error: 12385.4521 - val_loss: 0.1164 - val_mean_absolute_percentage_error: 11394.5664\n",
      "Epoch 15/30\n",
      "119099/119099 [==============================] - 22s 183us/step - loss: 0.0157 - mean_absolute_percentage_error: 12367.9746 - val_loss: 0.1204 - val_mean_absolute_percentage_error: 13645.2266\n",
      "Epoch 16/30\n",
      "119099/119099 [==============================] - 21s 180us/step - loss: 0.0155 - mean_absolute_percentage_error: 11681.3721 - val_loss: 0.1181 - val_mean_absolute_percentage_error: 12821.8994\n",
      "Epoch 17/30\n",
      "119099/119099 [==============================] - 23s 189us/step - loss: 0.0153 - mean_absolute_percentage_error: 11904.2666 - val_loss: 0.1174 - val_mean_absolute_percentage_error: 13415.8037\n",
      "Epoch 18/30\n",
      "119099/119099 [==============================] - 23s 189us/step - loss: 0.0151 - mean_absolute_percentage_error: 11496.6074 - val_loss: 0.1182 - val_mean_absolute_percentage_error: 12212.0000\n",
      "Epoch 19/30\n",
      "119099/119099 [==============================] - 22s 182us/step - loss: 0.0150 - mean_absolute_percentage_error: 12151.1592 - val_loss: 0.1136 - val_mean_absolute_percentage_error: 13915.4365\n",
      "Epoch 20/30\n",
      "119099/119099 [==============================] - 22s 182us/step - loss: 0.0150 - mean_absolute_percentage_error: 11883.8613 - val_loss: 0.1201 - val_mean_absolute_percentage_error: 10271.0352\n",
      "Epoch 21/30\n",
      "119099/119099 [==============================] - 23s 190us/step - loss: 0.0148 - mean_absolute_percentage_error: 10864.9414 - val_loss: 0.1242 - val_mean_absolute_percentage_error: 11536.6670\n",
      "Epoch 22/30\n",
      "119099/119099 [==============================] - 22s 187us/step - loss: 0.0147 - mean_absolute_percentage_error: 10860.5020 - val_loss: 0.1266 - val_mean_absolute_percentage_error: 15254.7139\n",
      "Epoch 23/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0145 - mean_absolute_percentage_error: 10570.5205 - val_loss: 0.1305 - val_mean_absolute_percentage_error: 9654.6455\n",
      "Epoch 24/30\n",
      "119099/119099 [==============================] - 23s 195us/step - loss: 0.0145 - mean_absolute_percentage_error: 11045.6338 - val_loss: 0.1236 - val_mean_absolute_percentage_error: 11309.2588\n",
      "Epoch 25/30\n",
      "119099/119099 [==============================] - 22s 188us/step - loss: 0.0145 - mean_absolute_percentage_error: 11270.6455 - val_loss: 0.1240 - val_mean_absolute_percentage_error: 11115.9004\n",
      "Epoch 26/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0144 - mean_absolute_percentage_error: 10463.2158 - val_loss: 0.1149 - val_mean_absolute_percentage_error: 13711.0146\n",
      "Epoch 27/30\n",
      "119099/119099 [==============================] - 22s 187us/step - loss: 0.0143 - mean_absolute_percentage_error: 11386.9209 - val_loss: 0.1314 - val_mean_absolute_percentage_error: 11408.2715\n",
      "Epoch 28/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0142 - mean_absolute_percentage_error: 10375.8125 - val_loss: 0.1218 - val_mean_absolute_percentage_error: 13455.4043\n",
      "Epoch 29/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0143 - mean_absolute_percentage_error: 9837.4531 - val_loss: 0.1295 - val_mean_absolute_percentage_error: 10819.1777\n",
      "Epoch 30/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0141 - mean_absolute_percentage_error: 9594.1865 - val_loss: 0.1239 - val_mean_absolute_percentage_error: 10859.1221\n"
     ]
    }
   ],
   "source": [
    "model_name = \"second_model\"\n",
    "\n",
    "model = models.Sequential(name=model_name)\n",
    "\n",
    "model.add(layers.LSTM(units=50, activation=\"relu\", name=\"LSTM_1\", dropout=0.1, \n",
    "                      input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "                      return_sequences=True))\n",
    "\n",
    "model.add(layers.LSTM(units=100, activation=\"relu\", name=\"LSTM_2\", dropout=0.1))\n",
    "\n",
    "model.add(layers.Dense(units=200, activation=\"relu\", name=\"Dense_1\"))\n",
    "model.add(layers.Dropout(0.15, name=\"Dropout_1\"))\n",
    "\n",
    "model.add(layers.Dense(units=400, activation=\"relu\", name=\"Dense_2\"))\n",
    "model.add(layers.Dropout(0.25, name=\"Dropout_2\"))\n",
    "\n",
    "model.add(layers.Dense(units=50, activation=\"relu\", name=\"Dense_3\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation=\"tanh\", name=\"classifier\"))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", \n",
    "              loss=\"mae\", \n",
    "              metrics=[\"mean_absolute_percentage_error\"])\n",
    "model.summary()\n",
    "\n",
    "history =  model.fit(train_x, train_y,\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size, \n",
    "                     validation_data=(val_x, val_y))\n",
    "\n",
    "model_save_name = next_free_model_name(model_name)\n",
    "model_save_path = MODELS_DIR + \"/\" + model_save_name + \".h5\"\n",
    "model.save(model_save_path)\n",
    "\n",
    "history_save_path = MODELS_DIR + \"/\" + model_save_name + \".csv\"\n",
    "history_dataframe = pd.DataFrame(history.history)\n",
    "history_dataframe.to_csv(history_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR + \"/\" + \"second_model_000.h5\")\n",
    "loaded_history = pd.read_csv(MODELS_DIR + \"/\" + \"second_model_000.csv\", index_col=0)\n",
    "plot_losses(loaded_history)\n",
    "results = generate_verification_dataframe(model, test_x_segmented, test_y_segmented, test_tickers)\n",
    "plot_result_verification(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "premier-newport",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"third_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (LSTM)                (None, 14, 50)            11400     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 192,501\n",
      "Trainable params: 192,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 119099 samples, validate on 34460 samples\n",
      "Epoch 1/30\n",
      "119099/119099 [==============================] - 24s 202us/step - loss: 0.0439 - mean_absolute_percentage_error: 24561.3164 - val_loss: 0.0651 - val_mean_absolute_percentage_error: 15727.4424\n",
      "Epoch 2/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0255 - mean_absolute_percentage_error: 18720.9629 - val_loss: 0.0815 - val_mean_absolute_percentage_error: 14384.3848\n",
      "Epoch 3/30\n",
      "119099/119099 [==============================] - 22s 189us/step - loss: 0.0219 - mean_absolute_percentage_error: 16861.2637 - val_loss: 0.0692 - val_mean_absolute_percentage_error: 14316.2891\n",
      "Epoch 4/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0205 - mean_absolute_percentage_error: 14726.1719 - val_loss: 0.0793 - val_mean_absolute_percentage_error: 12630.3584\n",
      "Epoch 5/30\n",
      "119099/119099 [==============================] - 23s 190us/step - loss: 0.0195 - mean_absolute_percentage_error: 15548.6396 - val_loss: 0.0870 - val_mean_absolute_percentage_error: 10097.9941\n",
      "Epoch 6/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0189 - mean_absolute_percentage_error: 17889.9121 - val_loss: 0.0841 - val_mean_absolute_percentage_error: 12372.1777\n",
      "Epoch 7/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0184 - mean_absolute_percentage_error: 19413.6426 - val_loss: 0.0913 - val_mean_absolute_percentage_error: 10366.9629\n",
      "Epoch 8/30\n",
      "119099/119099 [==============================] - 23s 190us/step - loss: 0.0176 - mean_absolute_percentage_error: 12622.1895 - val_loss: 0.0849 - val_mean_absolute_percentage_error: 12211.0684\n",
      "Epoch 9/30\n",
      "119099/119099 [==============================] - 23s 191us/step - loss: 0.0172 - mean_absolute_percentage_error: 13105.0615 - val_loss: 0.0875 - val_mean_absolute_percentage_error: 9449.6592\n",
      "Epoch 10/30\n",
      "119099/119099 [==============================] - 22s 183us/step - loss: 0.0172 - mean_absolute_percentage_error: 11844.1543 - val_loss: 0.0889 - val_mean_absolute_percentage_error: 9084.6914\n",
      "Epoch 11/30\n",
      "119099/119099 [==============================] - 22s 186us/step - loss: 0.0165 - mean_absolute_percentage_error: 12166.0771 - val_loss: 0.0808 - val_mean_absolute_percentage_error: 10228.1895\n",
      "Epoch 12/30\n",
      "119099/119099 [==============================] - 22s 186us/step - loss: 0.0164 - mean_absolute_percentage_error: 11474.4658 - val_loss: 0.0820 - val_mean_absolute_percentage_error: 10106.0156\n",
      "Epoch 13/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0160 - mean_absolute_percentage_error: 10922.7158 - val_loss: 0.0746 - val_mean_absolute_percentage_error: 10676.8252\n",
      "Epoch 14/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0161 - mean_absolute_percentage_error: 11644.8887 - val_loss: 0.0878 - val_mean_absolute_percentage_error: 8561.4131\n",
      "Epoch 15/30\n",
      "119099/119099 [==============================] - 22s 188us/step - loss: 0.0158 - mean_absolute_percentage_error: 10780.6426 - val_loss: 0.0925 - val_mean_absolute_percentage_error: 9096.0322\n",
      "Epoch 16/30\n",
      "119099/119099 [==============================] - 22s 187us/step - loss: 0.0158 - mean_absolute_percentage_error: 11500.4795 - val_loss: 0.0926 - val_mean_absolute_percentage_error: 9645.6953\n",
      "Epoch 17/30\n",
      "119099/119099 [==============================] - 22s 183us/step - loss: 0.0156 - mean_absolute_percentage_error: 9972.2080 - val_loss: 0.0837 - val_mean_absolute_percentage_error: 10217.7354\n",
      "Epoch 18/30\n",
      "119099/119099 [==============================] - 22s 183us/step - loss: 0.0155 - mean_absolute_percentage_error: 11681.1436 - val_loss: 0.0819 - val_mean_absolute_percentage_error: 9254.0840\n",
      "Epoch 19/30\n",
      "119099/119099 [==============================] - 21s 178us/step - loss: 0.0155 - mean_absolute_percentage_error: 11976.2783 - val_loss: 0.0819 - val_mean_absolute_percentage_error: 8148.4722\n",
      "Epoch 20/30\n",
      "119099/119099 [==============================] - 22s 185us/step - loss: 0.0152 - mean_absolute_percentage_error: 11294.9531 - val_loss: 0.0919 - val_mean_absolute_percentage_error: 9743.6484\n",
      "Epoch 21/30\n",
      "119099/119099 [==============================] - 21s 178us/step - loss: 0.0152 - mean_absolute_percentage_error: 11128.2676 - val_loss: 0.0815 - val_mean_absolute_percentage_error: 10294.9688\n",
      "Epoch 22/30\n",
      "119099/119099 [==============================] - 22s 189us/step - loss: 0.0149 - mean_absolute_percentage_error: 12021.4902 - val_loss: 0.0831 - val_mean_absolute_percentage_error: 9823.8018\n",
      "Epoch 23/30\n",
      "119099/119099 [==============================] - 22s 188us/step - loss: 0.0149 - mean_absolute_percentage_error: 14531.6963 - val_loss: 0.0889 - val_mean_absolute_percentage_error: 8803.1729\n",
      "Epoch 24/30\n",
      "119099/119099 [==============================] - 22s 181us/step - loss: 0.0148 - mean_absolute_percentage_error: 10207.2803 - val_loss: 0.0798 - val_mean_absolute_percentage_error: 8977.9971\n",
      "Epoch 25/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0147 - mean_absolute_percentage_error: 10534.9561 - val_loss: 0.0835 - val_mean_absolute_percentage_error: 10168.0283\n",
      "Epoch 26/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0148 - mean_absolute_percentage_error: 10429.1377 - val_loss: 0.0847 - val_mean_absolute_percentage_error: 8168.5859\n",
      "Epoch 27/30\n",
      "119099/119099 [==============================] - 22s 187us/step - loss: 0.0148 - mean_absolute_percentage_error: 11291.4639 - val_loss: 0.0845 - val_mean_absolute_percentage_error: 9914.7725\n",
      "Epoch 28/30\n",
      "119099/119099 [==============================] - 22s 182us/step - loss: 0.0145 - mean_absolute_percentage_error: 9975.4600 - val_loss: 0.0858 - val_mean_absolute_percentage_error: 8264.3701\n",
      "Epoch 29/30\n",
      "119099/119099 [==============================] - 23s 193us/step - loss: 0.0144 - mean_absolute_percentage_error: 10119.6221 - val_loss: 0.0789 - val_mean_absolute_percentage_error: 8791.7510\n",
      "Epoch 30/30\n",
      "119099/119099 [==============================] - 22s 184us/step - loss: 0.0144 - mean_absolute_percentage_error: 13437.2822 - val_loss: 0.0943 - val_mean_absolute_percentage_error: 6970.4453\n"
     ]
    }
   ],
   "source": [
    "model_name = \"third_model\"\n",
    "\n",
    "model = models.Sequential(name=model_name)\n",
    "\n",
    "model.add(layers.LSTM(units=50, activation=\"relu\", name=\"LSTM_1\", dropout=0.1, \n",
    "                      input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "                      return_sequences=True))\n",
    "\n",
    "model.add(layers.LSTM(units=100, activation=\"relu\", name=\"LSTM_2\", dropout=0.1))\n",
    "\n",
    "# model.add(layers.LSTM(units=200, activation=\"relu\", name=\"LSTM_3\", dropout=0.15))\n",
    "\n",
    "model.add(layers.Dense(units=200, activation=\"relu\", name=\"Dense_1\"))\n",
    "model.add(layers.Dropout(0.20, name=\"Dropout_1\"))\n",
    "\n",
    "model.add(layers.Dense(units=400, activation=\"relu\", name=\"Dense_2\"))\n",
    "model.add(layers.Dropout(0.30, name=\"Dropout_2\"))\n",
    "\n",
    "model.add(layers.Dense(units=50, activation=\"relu\", name=\"Dense_3\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\", name=\"classifier\"))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", \n",
    "              loss=\"mae\", \n",
    "              metrics=[\"mean_absolute_percentage_error\"])\n",
    "model.summary()\n",
    "\n",
    "history =  model.fit(train_x, train_y,\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size, \n",
    "                     validation_data=(val_x, val_y))\n",
    "\n",
    "model_save_name = next_free_model_name(model_name)\n",
    "model_save_path = MODELS_DIR + \"/\" + model_save_name + \".h5\"\n",
    "model.save(model_save_path)\n",
    "\n",
    "history_save_path = MODELS_DIR + \"/\" + model_save_name + \".csv\"\n",
    "history_dataframe = pd.DataFrame(history.history)\n",
    "history_dataframe.to_csv(history_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR + \"/\" + \"third_model_000.h5\")\n",
    "loaded_history = pd.read_csv(MODELS_DIR + \"/\" + \"third_model_000.csv\", index_col=0)\n",
    "plot_losses(loaded_history)\n",
    "results = generate_verification_dataframe(model, test_x_segmented, test_y_segmented, test_tickers)\n",
    "plot_result_verification(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "exciting-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_to_process = 500\n",
    "tickers = prices.symbol.unique()[:companies_to_process]\n",
    "\n",
    "company_data = []\n",
    "for ticker in tickers:\n",
    "    stock_price = prices[prices[\"symbol\"] == ticker]\n",
    "    new_indicators = pd.DataFrame()\n",
    "    \n",
    "    new_indicators[\"OBV\"] = ta.volume.on_balance_volume(stock_price[\"close\"], stock_price[\"volume\"])\n",
    "    \n",
    "    indicator = ta.volume.AccDistIndexIndicator(stock_price[\"high\"], stock_price[\"low\"],\n",
    "                                            stock_price[\"close\"], stock_price[\"volume\"])\n",
    "    new_indicators[\"ADI\"] = indicator.acc_dist_index()\n",
    "    \n",
    "    indicator = ta.trend.AroonIndicator(stock_price[\"close\"])\n",
    "    new_indicators[\"AI\"]  = indicator.aroon_indicator()\n",
    "    \n",
    "    indicator = ta.momentum.RSIIndicator(close=stock_price[\"close\"], window=14)\n",
    "    new_indicators[\"RSI\"] = indicator.rsi()\n",
    "    \n",
    "    indicator = ta.volume.VolumeWeightedAveragePrice(stock_price[\"high\"], stock_price[\"low\"], \n",
    "                                     stock_price[\"close\"],stock_price[\"volume\"], window=14)\n",
    "    new_indicators[\"VWAP\"] = indicator.volume_weighted_average_price()\n",
    "    \n",
    "    new_indicators[\"close\"] = stock_price[\"close\"]\n",
    "    new_indicators = new_indicators.to_numpy()\n",
    "    \n",
    "    company_data.append(new_indicators)\n",
    "\n",
    "company_data = np.array(company_data, dtype=object)\n",
    "price_data=company_data\n",
    "\n",
    "new_price_data = []\n",
    "for company in price_data:\n",
    "    new_comapny = company[~np.isnan(company).any(axis=1)]\n",
    "    new_price_data.append(new_comapny)\n",
    "\n",
    "price_data = np.array(new_price_data, dtype=object)\n",
    "scaled_price_data, scalers = scale_3d_price_data(price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "lucky-morocco",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmented train_x: (350,)\n",
      "Segmented rain_y: (350,)\n",
      "---------------------------------\n",
      "Segmented val_x:   (100, 1723, 14, 6)\n",
      "Segmented val_y:   (100, 1723, 1)\n",
      "---------------------------------\n",
      "Segmented test_x:  (50,)\n",
      "Segmented test_y:  (50,)\n",
      "---------------------------------\n",
      "Train_x:  (601539, 14, 6)\n",
      "Train_y:  (601539, 1)\n",
      "---------------------------------\n",
      "Val_x:   (172300, 14, 6)\n",
      "Val_y:   (172300, 1)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 14\n",
    "predicted_values = -1 # last value in \n",
    "data_split = (0.7, 0.2, 0.1)\n",
    "\n",
    "# price_data = np.array([0,1,2,3,4,5,6,7,8,9,10,11])\n",
    "train_data_length = (0, round(data_split[0] * scaled_price_data.shape[0]))\n",
    "val_data_length = (train_data_length[1], train_data_length[1] + round(data_split[1] * scaled_price_data.shape[0]))\n",
    "test_data_length = (val_data_length[1], val_data_length[1] + round(data_split[2] * scaled_price_data.shape[0]))\n",
    "\n",
    "input_data, output_data = [], []\n",
    "for company in scaled_price_data:\n",
    "    input_data.append(generate_input_sequences(data=company, input_length=sequence_length))\n",
    "    output_data.append(generate_output_sequences(data=company, input_length=sequence_length, \n",
    "                                                 outputs=predicted_values))\n",
    "\n",
    "train_x_segmented = np.array(input_data[train_data_length[0]:train_data_length[1]], dtype=object)\n",
    "train_y_segmented = np.array(output_data[train_data_length[0]:train_data_length[1]], dtype=object)\n",
    "train_scalers = scalers[train_data_length[0]:train_data_length[1]]\n",
    "train_tickers = tickers[train_data_length[0]:train_data_length[1]]\n",
    "\n",
    "val_x_segmented = np.array(input_data[val_data_length[0]:val_data_length[1]], dtype=object)\n",
    "val_y_segmented = np.array(output_data[val_data_length[0]:val_data_length[1]], dtype=object)\n",
    "val_scalers = scalers[val_data_length[0]:val_data_length[1]]\n",
    "val_tickers = tickers[val_data_length[0]:val_data_length[1]]\n",
    "\n",
    "test_x_segmented = np.array(input_data[test_data_length[0]:test_data_length[1]], dtype=object)\n",
    "test_y_segmented = np.array(output_data[test_data_length[0]:test_data_length[1]], dtype=object)\n",
    "test_scalers = scalers[test_data_length[0]:test_data_length[1]]\n",
    "test_tickers = tickers[test_data_length[0]:test_data_length[1]]\n",
    "train_x = flatten_data(train_x_segmented)\n",
    "train_y = flatten_data(train_y_segmented)\n",
    "\n",
    "val_x = flatten_data(val_x_segmented)\n",
    "val_y = flatten_data(val_y_segmented)\n",
    "\n",
    "print(f\"Segmented train_x: {train_x_segmented.shape}\")\n",
    "print(f\"Segmented rain_y: {train_y_segmented.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Segmented val_x:   {val_x_segmented.shape}\")\n",
    "print(f\"Segmented val_y:   {val_y_segmented.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Segmented test_x:  {test_x_segmented.shape}\")\n",
    "print(f\"Segmented test_y:  {test_y_segmented.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Train_x:  {train_x.shape}\")\n",
    "print(f\"Train_y:  {train_y.shape}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Val_x:   {val_x.shape}\")\n",
    "print(f\"Val_y:   {val_y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "stock-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"max_data_large_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_1 (LSTM)                (None, 14, 50)            11400     \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 14, 100)           60400     \n",
      "_________________________________________________________________\n",
      "LSTM_3 (LSTM)                (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 50)                20050     \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 453,301\n",
      "Trainable params: 453,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 601539 samples, validate on 172300 samples\n",
      "Epoch 1/30\n",
      "601539/601539 [==============================] - 93s 155us/step - loss: 0.0317 - mean_absolute_percentage_error: 26580.0742 - val_loss: 0.0706 - val_mean_absolute_percentage_error: 12643.1035\n",
      "Epoch 2/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0192 - mean_absolute_percentage_error: 16196.3252 - val_loss: 0.0914 - val_mean_absolute_percentage_error: 9554.0352\n",
      "Epoch 3/30\n",
      "601539/601539 [==============================] - 92s 154us/step - loss: 0.0175 - mean_absolute_percentage_error: 15987.0146 - val_loss: 0.0850 - val_mean_absolute_percentage_error: 9909.9072\n",
      "Epoch 4/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0167 - mean_absolute_percentage_error: 13835.0156 - val_loss: 0.0918 - val_mean_absolute_percentage_error: 9379.1162\n",
      "Epoch 5/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0162 - mean_absolute_percentage_error: 13401.5645 - val_loss: 0.0844 - val_mean_absolute_percentage_error: 9320.0176\n",
      "Epoch 6/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0159 - mean_absolute_percentage_error: 12507.7988 - val_loss: 0.0847 - val_mean_absolute_percentage_error: 8301.8232\n",
      "Epoch 7/30\n",
      "601539/601539 [==============================] - 92s 152us/step - loss: 0.0154 - mean_absolute_percentage_error: 11744.4346 - val_loss: 0.0900 - val_mean_absolute_percentage_error: 7455.2393\n",
      "Epoch 8/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0151 - mean_absolute_percentage_error: 12360.6250 - val_loss: 0.0918 - val_mean_absolute_percentage_error: 8948.8164\n",
      "Epoch 9/30\n",
      "601539/601539 [==============================] - 90s 149us/step - loss: 0.0149 - mean_absolute_percentage_error: 12220.9756 - val_loss: 0.0956 - val_mean_absolute_percentage_error: 6797.9111\n",
      "Epoch 10/30\n",
      "601539/601539 [==============================] - 91s 152us/step - loss: 0.0147 - mean_absolute_percentage_error: 11209.6953 - val_loss: 0.0940 - val_mean_absolute_percentage_error: 6366.3257\n",
      "Epoch 11/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0144 - mean_absolute_percentage_error: 11064.3877 - val_loss: 0.1025 - val_mean_absolute_percentage_error: 6252.7964\n",
      "Epoch 12/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0144 - mean_absolute_percentage_error: 11506.9248 - val_loss: 0.0967 - val_mean_absolute_percentage_error: 7773.7563\n",
      "Epoch 13/30\n",
      "601539/601539 [==============================] - 89s 148us/step - loss: 0.0143 - mean_absolute_percentage_error: 11181.1455 - val_loss: 0.0989 - val_mean_absolute_percentage_error: 6619.7646\n",
      "Epoch 14/30\n",
      "601539/601539 [==============================] - 92s 152us/step - loss: 0.0142 - mean_absolute_percentage_error: 10899.0273 - val_loss: 0.1060 - val_mean_absolute_percentage_error: 8329.8350\n",
      "Epoch 15/30\n",
      "601539/601539 [==============================] - 90s 149us/step - loss: 0.0141 - mean_absolute_percentage_error: 10459.6719 - val_loss: 0.1074 - val_mean_absolute_percentage_error: 5732.8306\n",
      "Epoch 16/30\n",
      "601539/601539 [==============================] - 90s 149us/step - loss: 0.0140 - mean_absolute_percentage_error: 10347.9326 - val_loss: 0.1073 - val_mean_absolute_percentage_error: 6610.9512\n",
      "Epoch 17/30\n",
      "601539/601539 [==============================] - 91s 152us/step - loss: 0.0139 - mean_absolute_percentage_error: 10388.7363 - val_loss: 0.1096 - val_mean_absolute_percentage_error: 6823.4224\n",
      "Epoch 18/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0139 - mean_absolute_percentage_error: 10333.4766 - val_loss: 0.1103 - val_mean_absolute_percentage_error: 6154.0005\n",
      "Epoch 19/30\n",
      "601539/601539 [==============================] - 92s 152us/step - loss: 0.0139 - mean_absolute_percentage_error: 10490.2070 - val_loss: 0.1126 - val_mean_absolute_percentage_error: 7792.3101\n",
      "Epoch 20/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0138 - mean_absolute_percentage_error: 11807.9570 - val_loss: 0.1144 - val_mean_absolute_percentage_error: 7128.8008\n",
      "Epoch 21/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0137 - mean_absolute_percentage_error: 10088.8379 - val_loss: 0.1119 - val_mean_absolute_percentage_error: 7081.3174\n",
      "Epoch 22/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0136 - mean_absolute_percentage_error: 10128.5508 - val_loss: 0.1112 - val_mean_absolute_percentage_error: 7375.1816\n",
      "Epoch 23/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0136 - mean_absolute_percentage_error: 9513.9092 - val_loss: 0.1141 - val_mean_absolute_percentage_error: 6345.1040\n",
      "Epoch 24/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0136 - mean_absolute_percentage_error: 9896.3174 - val_loss: 0.1156 - val_mean_absolute_percentage_error: 7174.4209\n",
      "Epoch 25/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0135 - mean_absolute_percentage_error: 10024.7207 - val_loss: 0.1160 - val_mean_absolute_percentage_error: 6105.0825\n",
      "Epoch 26/30\n",
      "601539/601539 [==============================] - 91s 152us/step - loss: 0.0135 - mean_absolute_percentage_error: 9724.3975 - val_loss: 0.1170 - val_mean_absolute_percentage_error: 6976.2861\n",
      "Epoch 27/30\n",
      "601539/601539 [==============================] - 89s 149us/step - loss: 0.0135 - mean_absolute_percentage_error: 10496.2041 - val_loss: 0.1205 - val_mean_absolute_percentage_error: 5591.7856\n",
      "Epoch 28/30\n",
      "601539/601539 [==============================] - 90s 150us/step - loss: 0.0135 - mean_absolute_percentage_error: 10574.3916 - val_loss: 0.1209 - val_mean_absolute_percentage_error: 6942.5244\n",
      "Epoch 29/30\n",
      "601539/601539 [==============================] - 91s 151us/step - loss: 0.0134 - mean_absolute_percentage_error: 9499.2412 - val_loss: 0.1189 - val_mean_absolute_percentage_error: 6724.4209\n",
      "Epoch 30/30\n",
      "601539/601539 [==============================] - 92s 152us/step - loss: 0.0134 - mean_absolute_percentage_error: 11111.8174 - val_loss: 0.1193 - val_mean_absolute_percentage_error: 6203.4995\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batch_size=512\n",
    "model_name = \"max_data_large_model\"\n",
    "\n",
    "model = models.Sequential(name=model_name)\n",
    "\n",
    "model.add(layers.LSTM(units=50, activation=\"relu\", name=\"LSTM_1\", dropout=0.1, \n",
    "                      input_shape=(train_x.shape[1], train_x.shape[2]), \n",
    "                      return_sequences=True))\n",
    "\n",
    "model.add(layers.LSTM(units=100, activation=\"relu\", name=\"LSTM_2\", dropout=0.1, return_sequences=True))\n",
    "\n",
    "model.add(layers.LSTM(units=200, activation=\"relu\", name=\"LSTM_3\", dropout=0.2))\n",
    "\n",
    "model.add(layers.Dense(units=200, activation=\"relu\", name=\"Dense_1\"))\n",
    "model.add(layers.Dropout(0.20, name=\"Dropout_1\"))\n",
    "\n",
    "model.add(layers.Dense(units=400, activation=\"relu\", name=\"Dense_2\"))\n",
    "model.add(layers.Dropout(0.30, name=\"Dropout_2\"))\n",
    "\n",
    "model.add(layers.Dense(units=50, activation=\"relu\", name=\"Dense_3\"))\n",
    "\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\", name=\"classifier\"))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", \n",
    "              loss=\"mae\", \n",
    "              metrics=[\"mean_absolute_percentage_error\"])\n",
    "model.summary()\n",
    "\n",
    "history =  model.fit(train_x, train_y,\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size, \n",
    "                     validation_data=(val_x, val_y))\n",
    "\n",
    "model_save_name = next_free_model_name(model_name)\n",
    "model_save_path = MODELS_DIR + \"/\" + model_save_name + \".h5\"\n",
    "model.save(model_save_path)\n",
    "\n",
    "history_save_path = MODELS_DIR + \"/\" + model_save_name + \".csv\"\n",
    "history_dataframe = pd.DataFrame(history.history)\n",
    "history_dataframe.to_csv(history_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(MODELS_DIR + \"/\" + \"max_data_large_model_000.h5\")\n",
    "loaded_history = pd.read_csv(MODELS_DIR + \"/\" + \"max_data_large_model_000.csv\", index_col=0)\n",
    "plot_losses(loaded_history)\n",
    "results = generate_verification_dataframe(model, test_x_segmented, test_y_segmented, test_tickers)\n",
    "plot_result_verification(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
